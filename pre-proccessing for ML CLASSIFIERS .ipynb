{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a993c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boso awlan keda i splitted el data bta3tna b test_size=0.2 w 7ttohom fe folders f m7dsh yst5dem train test split \n",
    "#ely mn sklearn alshan khalas el data already b2t m2sooma , est5dmt normalization alshan y fit el classifiers bdal hog da alshan \n",
    "# el doctor myfdalsh ys2al as2la r5ma w elmwdoo3 da a7na m5dnahoosh m3ah abl keda f ana l2et el normaliation\n",
    "#m7a2a bezbt nafs el hog da m722o w 3mlt flatten bardo alshan y5osh fl classifiers mn 8eir ay errors \n",
    "#w el smote da tare2a alshan bs el data mknstsh imbalanced f lazem nesta5dem el technique da alshan el data \n",
    "#tb2a balanced ben el classes w tb2at el label enocder ll labels bta3tna\n",
    "#0 to the label 'fake' and the integer 1 to the label 'real'.\n",
    "# w 3mlt resize ll images yaret m7dsh y8yro alshan lazem ykoon nafs el haga 3ndna kolna size 224 224 w el sewar rgb , el sewar aslun \n",
    "#kant 300 300 \n",
    "# w el slamo 3lykom w ra7mot allah w brkato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ce497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cf0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the paths to the input directories\n",
    "train_dir = \"C:/Users/Dell/University/Machine learning/Face_splittedData/train\"\n",
    "test_dir =  \"C:/Users/Dell/University/Machine learning/Face_splittedData/test\"\n",
    "\n",
    "# Set up the image dimensions\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Set up the HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "channel_axis = -1   \n",
    "\n",
    "# Define a function to preprocess the images\n",
    "def preprocess_images(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.jpg'):\n",
    "                    img_path = os.path.join(class_dir, file_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.resize(img, (img_height, img_width))\n",
    "                    X.append(img)\n",
    "                    y.append(class_name)\n",
    "                    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Normalize the data using mean and standard deviation and we applied the normalization before the oversamling to prevent data leakage\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.reshape(X.shape[0], -1))\n",
    "    X = X.reshape(-1, img_height, img_width, 3)\n",
    "    \n",
    "    # Apply SMOTE to balance the classes(oversambling as our data is imbalanced)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X.reshape(X.shape[0], -1), y)\n",
    "    X_resampled = X_resampled.reshape(-1, img_height, img_width, 3)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    # Perform label encoding on the target variable (labels)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_resampled = label_encoder.fit_transform(y_resampled)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4e9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "train_X, train_y = preprocess_images(train_dir)\n",
    "\n",
    "# Preprocess the testing data\n",
    "test_X, test_y = preprocess_images(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b368626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply flatten to convert 3-dimensional to 2-dimension \n",
    "train_X_flat = np.array([img.flatten() for img in train_X])\n",
    "test_X_flat = np.array([img.flatten() for img in test_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train ur classifier here using train_X_flat and test_X_flat for prediction and use test_y and train_y 3ady >>>good luck w 7asal 5eir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
